{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_objects(image_path, min_area=1000):\n",
    "    \"\"\"\n",
    "    Extract objects from an image using contours.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image.\n",
    "        min_area (int): Minimum area of the contour to be considered an object.\n",
    "    \n",
    "    Returns:\n",
    "        list: List of object images.\n",
    "    \"\"\"\n",
    "\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(\"Unable to read the image\")\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect edges using Canny\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "    # Dilate edges to connect broken lines\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    dilated = cv2.dilate(edges, kernel, iterations=2)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    objects = []\n",
    "    for i, contour in enumerate(contours):\n",
    "        # Filter out small contours\n",
    "        if cv2.contourArea(contour) < min_area:\n",
    "            continue\n",
    "        \n",
    "        # Get bounding rectangle\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        \n",
    "        # Add padding and ensure within image bounds\n",
    "        x = max(0, x)\n",
    "        y = max(0, y)\n",
    "        w = min(image.shape[1] - x, w)\n",
    "        h = min(image.shape[0] - y, h)\n",
    "        \n",
    "        # Extract object image\n",
    "        object_img = image[y:y+h, x:x+w]\n",
    "        objects.append(object_img)\n",
    "\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def template_matching_with_mask(main_image_path, objects, mask_threshold=230, scales=np.linspace(0.4, 1.0, 20)):\n",
    "    \"\"\"\n",
    "    Perform template matching with mask on multiple object images.\n",
    "    \n",
    "    Args:\n",
    "    main_image_path (str): Path to the main image.\n",
    "    objects (list): List of object images.\n",
    "    mask_threshold (int): Threshold for creating the mask.\n",
    "    scales (numpy.ndarray): Array of scale factors for resizing.\n",
    "    \n",
    "    Returns:\n",
    "    list: List of best match details for each object (position, size, correlation).\n",
    "    \"\"\"\n",
    "    main_image = cv2.imread(main_image_path)\n",
    "    if main_image is None:\n",
    "        raise ValueError(\"Unable to read the main image\")\n",
    "    \n",
    "    main_gray = cv2.cvtColor(main_image, cv2.COLOR_BGR2GRAY)\n",
    "    best_matches = []\n",
    "\n",
    "    for i, obj in enumerate(objects):\n",
    "        object_gray = cv2.cvtColor(obj, cv2.COLOR_BGR2GRAY)\n",
    "        object_mask = (object_gray < mask_threshold).astype(np.uint8)\n",
    "        \n",
    "        best_match = find_best_match(main_gray, object_gray, object_mask, scales)\n",
    "        best_matches.append(best_match)\n",
    "        draw_result(main_image, best_match, i)\n",
    "\n",
    "    task_index = main_image_path[-5]\n",
    "    result_name = f'result_{task_index}.jpg'\n",
    "    cv2.imwrite(result_name, main_image)\n",
    "    return best_matches\n",
    "\n",
    "def find_best_match(main_gray, object_gray, object_mask, scales):\n",
    "    \"\"\"\n",
    "    Find the best match for an object in the main image across different scales.\n",
    "    \n",
    "    Args:\n",
    "    main_gray (numpy.ndarray): Grayscale main image.\n",
    "    object_gray (numpy.ndarray): Grayscale object image.\n",
    "    object_mask (numpy.ndarray): Binary mask of the object.\n",
    "    scales (numpy.ndarray): Array of scale factors for resizing.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Best match details (position, size, correlation).\n",
    "    \"\"\"\n",
    "    best_val = float('inf')\n",
    "    best_match = None\n",
    "\n",
    "    for scale in scales:\n",
    "        resized_object = cv2.resize(object_gray, None, fx=scale, fy=scale)\n",
    "        resized_mask = cv2.resize(object_mask, None, fx=scale, fy=scale)\n",
    "        h, w = resized_object.shape\n",
    "\n",
    "        result = cv2.matchTemplate(main_gray, resized_object, cv2.TM_SQDIFF_NORMED, mask=resized_mask)\n",
    "        min_val, _, min_loc, _ = cv2.minMaxLoc(result)\n",
    "\n",
    "        if min_val < best_val:\n",
    "            best_val = min_val\n",
    "            best_match = (min_loc, (h, w), 1 - min_val)\n",
    "\n",
    "    return best_match\n",
    "\n",
    "def draw_result(main_image, match, i):\n",
    "    \"\"\"\n",
    "    Draw the best match result on the main image.\n",
    "    \n",
    "    Args:\n",
    "    main_image (numpy.ndarray): Main image to draw on.\n",
    "    match (tuple): Match details (position, size, correlation score).\n",
    "    i (int): Object index.\n",
    "    \"\"\"\n",
    "    pt, (h, w), score = match\n",
    "    cv2.rectangle(main_image, pt, (pt[0] + w, pt[1] + h), (0, 0, 0), 5)\n",
    "    cv2.putText(main_image, f\"object_{i} ({score:.2f})\", (pt[0], pt[1] - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 0), 3)\n",
    "\n",
    "def overlaps(match1, match2, overlap_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Check if two matches overlap.\n",
    "    \n",
    "    Args:\n",
    "    match1, match2 (tuple): Match details.\n",
    "    overlap_threshold (float): Threshold for considering overlap.\n",
    "    \n",
    "    Returns:\n",
    "    bool: True if matches overlap, False otherwise.\n",
    "    \"\"\"\n",
    "    _, (x1, y1), (h1, w1), _ = match1\n",
    "    _, (x2, y2), (h2, w2), _ = match2\n",
    "    \n",
    "    intersection_width = max(0, min(x1 + w1, x2 + w2) - max(x1, x2))\n",
    "    intersection_height = max(0, min(y1 + h1, y2 + h2) - max(y1, y2))\n",
    "    intersection_area = intersection_width * intersection_height\n",
    "    \n",
    "    area1 = w1 * h1\n",
    "    area2 = w2 * h2\n",
    "    \n",
    "    overlap_ratio = intersection_area / min(area1, area2)\n",
    "    \n",
    "    return overlap_ratio > overlap_threshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1\n",
    "objects_1 = extract_objects('objects_to_find_1.jpg')\n",
    "main_image_path_1 = 'main_image_1.jpg'\n",
    "results = template_matching_with_mask(main_image_path_1, objects_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2\n",
    "objects_2 = extract_objects('objects_to_find_2.jpg')\n",
    "main_image_path_2 = 'main_image_2.jpg'\n",
    "results = template_matching_with_mask(main_image_path_2, objects_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
